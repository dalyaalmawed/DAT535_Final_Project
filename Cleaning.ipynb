{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkContext\n",
    "sc = SparkContext(\"local\", \"Data Cleaning with Basic Routines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for loading data\n",
    "txt_path_music = \"hdfs:///mydata/music_info_unstructured_semicolon.txt\"  \n",
    "txt_path_history = \"hdfs:///mydata/user_listening_history_unstructured_semicolon.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets as RDDs\n",
    "rdd_music = sc.textFile(txt_path_music)\n",
    "print(rdd_music.getNumPartitions())  # Number of partitions based on file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "rdd_history = sc.textFile(txt_path_history)\n",
    "print(rdd_history.getNumPartitions())  # Number of partitions based on file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original music_info record count: 50683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original user_listening_history record count: 9711301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initial profiling: Count original records\n",
    "print(f\"Original music_info record count: {rdd_music.count()}\")\n",
    "print(f\"Original user_listening_history record count: {rdd_history.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRIOREW128F424EAF0;Mr. Brightside;The Killers;https://p.scdn.co/mp3-preview/4d26180e6961fd46866cd9106936ea55dfcbaa75?cid=774b29d4f13844c495f206cafdad9c86;09ZQ5TmUG8TSL56n0knqrj;rock, alternative, indie, alternative_rock, indie_rock, 00s;;2004;222200;0.355;0.918;1;-4.36;1;0.0746;0.00119;0.0;0.0971;0.24;148.114;4',\n",
       " 'TRRIVDJ128F429B0E8;Wonderwall;Oasis;https://p.scdn.co/mp3-preview/d012e536916c927bd6c8ced0dae75ee3b7715983?cid=774b29d4f13844c495f206cafdad9c86;06UfBBDISthj1ZJAtX4xjj;rock, alternative, indie, pop, alternative_rock, british, 90s, love, britpop;;2006;258613;0.409;0.892;2;-4.373;1;0.0336;0.000807;0.0;0.207;0.651;174.426;4',\n",
       " 'TROUVHL128F426C441;Come as You Are;Nirvana;https://p.scdn.co/mp3-preview/a1c11bb1cb231031eb20e5951a8bfb30503224e9?cid=774b29d4f13844c495f206cafdad9c86;0keNu0t0tqsWtExGM3nT1D;rock, alternative, alternative_rock, 90s, grunge;RnB;1991;218920;0.508;0.826;4;-5.783;0;0.04;0.000175;0.000459;0.0878;0.543;120.012;4',\n",
       " 'TRUEIND128F93038C4;Take Me Out;Franz Ferdinand;https://p.scdn.co/mp3-preview/399c401370438be449c2aebff816ba8c62559871?cid=774b29d4f13844c495f206cafdad9c86;0ancVQ9wEcHVd0RrGICTE4;rock, alternative, indie, alternative_rock, indie_rock, british, 00s, britpop;;2004;237026;0.279;0.664;9;-8.851;1;0.0371;0.000389;0.000655;0.133;0.49;104.56;4',\n",
       " 'TRLNZBD128F935E4D8;Creep;Radiohead;https://p.scdn.co/mp3-preview/e7eb60e9466bc3a27299ea8803aadf4fa9cf795c?cid=774b29d4f13844c495f206cafdad9c86;01QoK9DA7VTeTSE3MNzp4I;rock, alternative, indie, alternative_rock, indie_rock, british, 90s, britpop;RnB;2008;238640;0.515;0.43;7;-9.935;1;0.0369;0.0102;0.000141;0.129;0.104;91.841;4']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_music.take(5)  # Review the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRIRLYL128F42539D1;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1',\n",
       " 'TRFUPBA128F934F7E1;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1',\n",
       " 'TRLQPQJ128F42AA94F;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1',\n",
       " 'TRTUCUY128F92E1D24;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1',\n",
       " 'TRHDDQG12903CB53EE;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_history.take(5)  # Review the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hdfs:///mydata/user_listening_history_unstructured_semicolon.txt MapPartitionsRDD[3] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caching the data after counting to avoid re-computation\n",
    "rdd_music.cache()\n",
    "rdd_history.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "expected_column_count_music = 21  \n",
    "expected_column_count_history = 3\n",
    "essential_indexes_music = [0]  # track_id for music_info\n",
    "essential_indexes_history = [0, 1]  # track_id and user_id for user_listening_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and profiling function\n",
    "def basic_cleaning(rdd, expected_count, essential_indexes):\n",
    "    # Step 1: Remove duplicates\n",
    "    rdd = rdd.distinct()\n",
    "    print(f\"Record count after removing duplicates: {rdd.count()}\")\n",
    "    \n",
    "    # Step 2: Filter rows with the correct column count\n",
    "    rdd = rdd.filter(lambda line: len(line.split(\";\")) == expected_count)\n",
    "    print(f\"Record count after column count verification: {rdd.count()}\")\n",
    "    \n",
    "    # Step 3: Filter rows where essential fields are not null\n",
    "    rdd = rdd.filter(lambda line: all(line.split(\";\")[index] != \"\" for index in essential_indexes))\n",
    "    print(f\"Record count after filtering essential non-null fields: {rdd.count()}\")\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cleaning operations for music_info dataset...\n",
      "Record count after removing duplicates: 50683\n",
      "Record count after column count verification: 50681\n",
      "Record count after filtering essential non-null fields: 50681\n",
      "Cleaning operations for music_info dataset completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning operations to the music_info dataset\n",
    "print(\"Starting cleaning operations for music_info dataset...\")\n",
    "rdd_music_cleaned = basic_cleaning(rdd_music, expected_column_count_music, essential_indexes_music)\n",
    "print(\"Cleaning operations for music_info dataset completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cleaning operations for user_listening_history dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count after removing duplicates: 9711301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count after column count verification: 9711301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record count after filtering essential non-null fields: 9711301\n",
      "Cleaning operations for user_listening_history dataset completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply cleaning operations to the user_listening_history dataset\n",
    "print(\"Starting cleaning operations for user_listening_history dataset...\")\n",
    "rdd_history_cleaned = basic_cleaning(rdd_history, expected_column_count_history, essential_indexes_history)\n",
    "print(\"Cleaning operations for user_listening_history dataset completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row from cleaned music_info dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TRRIVDJ128F429B0E8;Wonderwall;Oasis;https://p.scdn.co/mp3-preview/d012e536916c927bd6c8ced0dae75ee3b7715983?cid=774b29d4f13844c495f206cafdad9c86;06UfBBDISthj1ZJAtX4xjj;rock, alternative, indie, pop, alternative_rock, british, 90s, love, britpop;;2006;258613;0.409;0.892;2;-4.373;1;0.0336;0.000807;0.0;0.207;0.651;174.426;4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First row from cleaned music_info dataset:\")\n",
    "rdd_music_cleaned.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row from cleaned user_listening_history dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TRAUCNU128F42671EB;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First row from cleaned user_listening_history dataset:\")\n",
    "rdd_history_cleaned.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace null values with \"Unknown\"\n",
    "def replace_nulls(line):\n",
    "    # Split the line into fields using semicolon as a delimiter\n",
    "    fields = line.split(\";\")\n",
    "    # Replace each empty field with \"Unknown\"\n",
    "    fields = [\"Unknown\" if field.strip() == \"\" else field for field in fields]\n",
    "    # Reconstruct the original line\n",
    "    return \";\".join(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRRIVDJ128F429B0E8;Wonderwall;Oasis;https://p.scdn.co/mp3-preview/d012e536916c927bd6c8ced0dae75ee3b7715983?cid=774b29d4f13844c495f206cafdad9c86;06UfBBDISthj1ZJAtX4xjj;rock, alternative, indie, pop, alternative_rock, british, 90s, love, britpop;Unknown;2006;258613;0.409;0.892;2;-4.373;1;0.0336;0.000807;0.0;0.207;0.651;174.426;4\n",
      "TROUVHL128F426C441;Come as You Are;Nirvana;https://p.scdn.co/mp3-preview/a1c11bb1cb231031eb20e5951a8bfb30503224e9?cid=774b29d4f13844c495f206cafdad9c86;0keNu0t0tqsWtExGM3nT1D;rock, alternative, alternative_rock, 90s, grunge;RnB;1991;218920;0.508;0.826;4;-5.783;0;0.04;0.000175;0.000459;0.0878;0.543;120.012;4\n",
      "TRUMISQ128F9340BEE;Somebody Told Me;The Killers;https://p.scdn.co/mp3-preview/0d07673cfb46218a49c96eed639933f19b45cf9c?cid=774b29d4f13844c495f206cafdad9c86;0FNmIQ7u45Lhdn6RHhSLix;rock, alternative, indie, pop, alternative_rock, indie_rock;Unknown;2005;198480;0.508;0.979;10;-4.289;0;0.0847;8.71e-05;0.000643;0.0641;0.704;138.03;4\n",
      "TRFNTDZ128F426B34D;In the End;Linkin Park;https://p.scdn.co/mp3-preview/6ce8bcf317e8c562f348ea22c846846b5b70e8d9?cid=774b29d4f13844c495f206cafdad9c86;138JuTi1U3WIROalXod9FB;rock, alternative, metal, alternative_rock, nu_metal;Unknown;2000;216933;0.542;0.853;3;-6.407;0;0.0498;0.0103;0.0;0.108;0.37;105.256;4\n",
      "TRCSXPV128F425E2F7;Chasing Cars;Snow Patrol;https://p.scdn.co/mp3-preview/f6718903c52c507068a15158552eab1f4d8da28f?cid=774b29d4f13844c495f206cafdad9c86;01Jvw9zNg5LM2RF8WNfnLy;rock, alternative, indie, pop, alternative_rock, indie_rock, british, love, beautiful, britpop, mellow;Unknown;2006;265573;0.558;0.568;9;-5.731;1;0.0267;0.211;5e-05;0.104;0.125;104.0;4\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to each line of the music RDD\n",
    "rdd_music_cleaned = rdd_music_cleaned.map(replace_nulls)\n",
    "\n",
    "# Check the result by displaying the first 5 lines\n",
    "for line in rdd_music_cleaned.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAUCNU128F42671EB;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1\n",
      "TRADVZX128F426BF79;b80344d063b5ccb3212f76538f3d9e43d87dca9e;1\n",
      "TRSGIYX128F149F01F;969cc6fb74e076a68e36a04409cb9d3765757508;1\n",
      "TRDSFKT12903CB510F;4bd88bfb25263a75bbdd467e74018f4ae570e5df;4\n",
      "TRUZPNY128F147FD23;e006b1a48f466bf59feefed32bec6494495a4436;1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply the function to each line of the history RDD\n",
    "rdd_history_cleaned = rdd_history_cleaned.map(replace_nulls)\n",
    "\n",
    "# Check the result by displaying the first 5 lines\n",
    "for line in rdd_history_cleaned.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"CSVtoTXT\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns from the cleaned music_info RDD\n",
    "columns_to_drop_indices = [3, 4, 8, 11, 13, 18, 19, 20]  # Indices of columns to drop\n",
    "cleaned_music_rdd = rdd_music_cleaned.map(lambda row: [val for idx, val in enumerate(row.split(\";\")) if idx not in columns_to_drop_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the music DataFrame\n",
    "columns_music = StructType([\n",
    "    StructField(\"track_id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"artist\", StringType(), True),\n",
    "    StructField(\"tags\", StringType(), True),\n",
    "    StructField(\"genre\", StringType(), True),\n",
    "    StructField(\"year\", StringType(), True),  # To be converted to IntegerType later\n",
    "    StructField(\"danceability\", StringType(), True),  # To be converted to FloatType\n",
    "    StructField(\"energy\", StringType(), True),  # To be converted to FloatType\n",
    "    StructField(\"loudness\", StringType(), True),  # To be converted to FloatType\n",
    "    StructField(\"speechiness\", StringType(), True),\n",
    "    StructField(\"acousticness\", StringType(), True),\n",
    "    StructField(\"instrumentalness\", StringType(), True),\n",
    "    StructField(\"liveness\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the music DataFrame with string types\n",
    "df_music_cleaned = spark.createDataFrame(cleaned_music_rdd, columns_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast columns to the correct types\n",
    "df_music_cleaned = df_music_cleaned \\\n",
    "    .withColumn(\"year\", df_music_cleaned[\"year\"].cast(IntegerType())) \\\n",
    "    .withColumn(\"danceability\", df_music_cleaned[\"danceability\"].cast(FloatType())) \\\n",
    "    .withColumn(\"energy\", df_music_cleaned[\"energy\"].cast(FloatType())) \\\n",
    "    .withColumn(\"loudness\", df_music_cleaned[\"loudness\"].cast(FloatType())) \\\n",
    "    .withColumn(\"speechiness\", df_music_cleaned[\"speechiness\"].cast(FloatType())) \\\n",
    "    .withColumn(\"acousticness\", df_music_cleaned[\"acousticness\"].cast(FloatType())) \\\n",
    "    .withColumn(\"instrumentalness\", df_music_cleaned[\"instrumentalness\"].cast(FloatType())) \\\n",
    "    .withColumn(\"liveness\", df_music_cleaned[\"liveness\"].cast(FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- energy: float (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- speechiness: float (nullable = true)\n",
      " |-- acousticness: float (nullable = true)\n",
      " |-- instrumentalness: float (nullable = true)\n",
      " |-- liveness: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema to make sure the types are correct\n",
    "df_music_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+------+----+-----+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "|track_id|name|artist|tags|genre|year|danceability|energy|loudness|speechiness|acousticness|instrumentalness|liveness|\n",
      "+--------+----+------+----+-----+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "|       0|   0|     0|   0|    0|   0|           0|     0|       0|          0|           0|               0|       0|\n",
      "+--------+----+------+----+-----+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null or empty values in each column of the music DataFrame\n",
    "df_music_cleaned.select([\n",
    "    F.count(F.when((F.col(c).isNull()) | (F.col(c) == ''), c)).alias(c) \n",
    "    for c in df_music_cleaned.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+-----------+------------------------------------------------------------------------------------------------------+-------+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "|track_id          |name            |artist     |tags                                                                                                  |genre  |year|danceability|energy|loudness|speechiness|acousticness|instrumentalness|liveness|\n",
      "+------------------+----------------+-----------+------------------------------------------------------------------------------------------------------+-------+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "|TRRIVDJ128F429B0E8|Wonderwall      |Oasis      |rock, alternative, indie, pop, alternative_rock, british, 90s, love, britpop                          |Unknown|2006|0.409       |0.892 |-4.373  |0.0336     |8.07E-4     |0.0             |0.207   |\n",
      "|TROUVHL128F426C441|Come as You Are |Nirvana    |rock, alternative, alternative_rock, 90s, grunge                                                      |RnB    |1991|0.508       |0.826 |-5.783  |0.04       |1.75E-4     |4.59E-4         |0.0878  |\n",
      "|TRUMISQ128F9340BEE|Somebody Told Me|The Killers|rock, alternative, indie, pop, alternative_rock, indie_rock                                           |Unknown|2005|0.508       |0.979 |-4.289  |0.0847     |8.71E-5     |6.43E-4         |0.0641  |\n",
      "|TRFNTDZ128F426B34D|In the End      |Linkin Park|rock, alternative, metal, alternative_rock, nu_metal                                                  |Unknown|2000|0.542       |0.853 |-6.407  |0.0498     |0.0103      |0.0             |0.108   |\n",
      "|TRCSXPV128F425E2F7|Chasing Cars    |Snow Patrol|rock, alternative, indie, pop, alternative_rock, indie_rock, british, love, beautiful, britpop, mellow|Unknown|2006|0.558       |0.568 |-5.731  |0.0267     |0.211       |5.0E-5          |0.104   |\n",
      "+------------------+----------------+-----------+------------------------------------------------------------------------------------------------------+-------+----+------------+------+--------+-----------+------------+----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_music_cleaned.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the cleaned user listening history RDD into individual fields based on semicolon (;) delimiter\n",
    "history_cleaned_rdd = rdd_history_cleaned.map(lambda line: line.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the history DataFrame\n",
    "columns_history =  StructType([\n",
    "    StructField(\"track_id\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"playcount\", StringType(), True) # To be converted to IntegerType later\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the history DataFrame with string types\n",
    "df_history_cleaned = spark.createDataFrame(history_cleaned_rdd, columns_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast columns to the correct types\n",
    "df_history_cleaned = df_history_cleaned \\\n",
    "    .withColumn(\"playcount\", df_history_cleaned[\"playcount\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- playcount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema to make sure the types are correct\n",
    "df_history_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---------+\n",
      "|track_id|user_id|playcount|\n",
      "+--------+-------+---------+\n",
      "|       0|      0|        0|\n",
      "+--------+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check for null or empty values in each column of the history DataFrame\n",
    "df_history_cleaned.select([\n",
    "    F.count(F.when((F.col(c).isNull()) | (F.col(c) == ''), c)).alias(c) \n",
    "    for c in df_history_cleaned.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------+---------+\n",
      "|track_id          |user_id                                 |playcount|\n",
      "+------------------+----------------------------------------+---------+\n",
      "|TRAUCNU128F42671EB|b80344d063b5ccb3212f76538f3d9e43d87dca9e|1        |\n",
      "|TRADVZX128F426BF79|b80344d063b5ccb3212f76538f3d9e43d87dca9e|1        |\n",
      "|TRSGIYX128F149F01F|969cc6fb74e076a68e36a04409cb9d3765757508|1        |\n",
      "|TRDSFKT12903CB510F|4bd88bfb25263a75bbdd467e74018f4ae570e5df|4        |\n",
      "|TRUZPNY128F147FD23|e006b1a48f466bf59feefed32bec6494495a4436|1        |\n",
      "+------------------+----------------------------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_history_cleaned.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrames back to HDFS in Parquet format\n",
    "cleaned_parquet_path_music = \"hdfs:///mydata/cleaned_music_info.parquet\"\n",
    "cleaned_parquet_path_history = \"hdfs:///mydata/cleaned_user_listening_history.parquet\"\n",
    "\n",
    "df_music_cleaned.write.mode('overwrite').parquet(cleaned_parquet_path_music)\n",
    "df_history_cleaned.write.mode('overwrite').parquet(cleaned_parquet_path_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkContent\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
